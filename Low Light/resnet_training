Cell 1:

!pip install kaggle --quiet

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

Cell 2:

from kaggle.api.kaggle_api_extended import KaggleApi

api = KaggleApi()
api.authenticate()

dataset = 'washingtongold/exdark-dataset'
api.dataset_download_files(dataset, path='data1/exdark', unzip=True)

Cell 3:

import os, shutil, random

random.seed(42)

root = "data/exdark" 
out_root = "data/exdark_split"

os.makedirs(out_root, exist_ok=True)
splits = ["train", "val", "test"]

for split in splits:
    os.makedirs(os.path.join(out_root, split), exist_ok=True)

for cls in os.listdir(root):
    cls_path = os.path.join(root, cls)
    if not os.path.isdir(cls_path):
        continue

    imgs = os.listdir(cls_path)
    random.shuffle(imgs)

    n = len(imgs)
    train_imgs = imgs[:int(0.7*n)]
    val_imgs   = imgs[int(0.7*n):int(0.85*n)]
    test_imgs  = imgs[int(0.85*n):]

    for split_name, split_list in zip(splits, [train_imgs, val_imgs, test_imgs]):
        out_cls_path = os.path.join(out_root, split_name, cls)
        os.makedirs(out_cls_path, exist_ok=True)
        for img in split_list:
            shutil.copy(os.path.join(cls_path, img),
                        os.path.join(out_cls_path, img))

Cell 4:

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

data_dir = "data/exdark_split"

train_data = datasets.ImageFolder(data_dir + "/train", transform=transform)
val_data   = datasets.ImageFolder(data_dir + "/val", transform=transform)
test_data  = datasets.ImageFolder(data_dir + "/test", transform=transform)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_data, batch_size=32, shuffle=False)
test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)

num_classes = len(train_data.classes)
print("Classes:", train_data.classes)
print("Num classes:", num_classes)

Cell 5:

import torch
import torch.nn as nn
from torchvision import models

model = models.resnet50(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, 12)

Cell 6:

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

for epoch in range(10):
    model.train()
    running_loss = 0

    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}")

torch.save(model.state_dict(), "resnet50_exdark2.pth")
print("Model saved!")

Cell 7:

model = models.resnet50(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, 12)
checkpoint_path = "resnet50_exdark.pth"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.load_state_dict(torch.load(checkpoint_path, map_location=device))
model.to(device)

Cell 8:

def evaluate(model, loader):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            _, preds = outputs.max(1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    return correct / total

print("Training accuracy:", evaluate(model, train_loader))
print("Validation accuracy:", evaluate(model, val_loader))
print("Test accuracy:", evaluate(model, test_loader))
